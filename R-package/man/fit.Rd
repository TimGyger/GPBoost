% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gpb.GPModel.R
\name{fit}
\alias{fit}
\title{Generic 'fit' method}
\usage{
fit(gp_model, y, X, std_dev = FALSE, params)
}
\arguments{
\item{gp_model}{a \code{gpb.GPModel}}

\item{y}{A \code{vector} with response variable data}

\item{X}{A \code{matrix} with covariate data for fixed effects ( = linear regression term)}

\item{std_dev}{If TRUE (asymptotic) standard deviations are calculated for all parameters}

\item{params}{A \code{list} with parameters for the model fitting / optimization
 \itemize{
    \item{optimizer_cov}{ Optimizer used for estimating covariance parameters. 
    Options: "gradient_descent" or "fisher_scoring" }
    \item{optimizer_coef}{ Optimizer used for estimating linear regression coefficients, if there are any 
    (for the GPBoost algorithm there are usually no). 
    Options: "gradient_descent" or "wls". Gradient descent steps are done simultaneously 
    with gradient descent steps for the covariance paramters. 
    "wls" refers to doing coordinate descent for the regression coefficients using weighted least squares.}
    \item{maxit}{ Maximal number of iterations for optimization algorithm}
    \item{delta_rel_conv}{ Convergence criterion: stop optimization if relative change 
    in parameters is below this value}
    \item{init_coef}{ Initial values for the regression coefficients (if there are any, can be NULL)}
    \item{init_cov_pars}{ Initial values for covariance parameters of Gaussian process and 
    random effects (can be NULL)}
    \item{lr_coef}{ Learning rate for fixed effect regression coefficients}
    \item{lr_cov}{ Learning rate for covariance parameters}
    \item{use_nesterov_acc}{ If TRUE Nesterov acceleration is used}
    \item{acc_rate_coef}{ Acceleration rate for regression coefficients (if there are any) for Nesterov acceleration}
    \item{acc_rate_cov}{ Acceleration rate for covariance parameters for Nesterov acceleration}
    \item{momentum_offset}{ Number of iterations for which no mometum is applied in the beginning}
    \item{trace}{ If TRUE, the value of the gradient is printed for some iterations.
    Useful for finding good learning rates.}
}}
}
\description{
Generic 'fit' method
}
